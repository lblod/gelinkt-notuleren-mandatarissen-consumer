# gelinkt-notuleren-mandatarissen-consumer

Consumer service to sync data about mandatees from external sources based on diff files generated by [mandatendatabank-mandatarissen-producer](http://github.com/lblod/mandatendatabank-mandatarissen-producer). At regular intervals the consumer checks for new diff files and ingests the data found in the files. The data is ingested in the appropriate graphs according to the authorization rules.

## Tutorials
### Add the service to a stack
Add the service to your `docker-compose.yml`:

```
  mandatarissen-consumer:
    image: lblod/gelinkt-notuleren-mandatarissen-consumer
    environment:
      SYNC_BASE_URL: 'https://mandatarissen.lblod.info # replace with link to Mandatatendatabank API
```

Change the `SYNC_BASE_URL` to the application hosting the producer server.

## Reference
### Configuration
The following environment variables are required:
* `SYNC_BASE_URL`: base URL of the stack hosting the producer API (e.g. http://mandaten.lblod.info/)

The following environment variables are optional:
* `SYNC_FILES_PATH (default: /sync/mandatarissen/files)`: relative path to the endpoint to retrieve names of the diff files from
* `DOWNLOAD_FILES_PATH (default: /files/:id/download)`: relative path to the endpoint to download a diff file from. `:id` will be replaced with the uuid of the file.
* `MU_APPLICATION_GRAPH (default: http://mu.semte.ch/application)`: target graph in which all data will be ingested
* `INGEST_INTERVAL (in ms, default: 60000)`: interval at which the consumer needs to sync data
* `START_FROM_DELTA_TIMESTAMP (ISO datetime, default: now)`: timestamp to start sync data from (e.g. "2020-07-05T13:57:36.344Z")

### Model
#### Used prefixes
| Prefix | URI                                                       |
|--------|-----------------------------------------------------------|
| dct    | http://purl.org/dc/terms/                                 |
| adms   | http://www.w3.org/ns/adms#                                |
| ext    | http://mu.semte.ch/vocabularies/ext                       |

#### Sync task
##### Class
`ext:SyncTask`
##### Properties
| Name       | Predicate        | Range           | Definition                                                                                                                                   |
|------------|------------------|-----------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| status     | `adms:status`    | `adms:Status`   | Status of the sync task, initially set to `<http://lblod.data.gift/gelinkt-notuleren-mandatarissen-consumer-sync-task-statuses/not-started>` |
| created    | `dct:created`    | `xsd:dateTime`  | Datetime of creation of the task                                                                                                             |
| creator    | `dct:creator`    | `rdfs:Resource` | Creator of the task, in this case the mandatendatabank-consumer `<http://lblod.data.gift/services/gelinkt-notuleren-mandatarissen-consumer>` |
| deltaUntil | `ext:deltaUntil` | `xsd:dateTime`  | Datetime of the latest successfully ingested sync file as part of the task execution                                                         |

#### Sync task statuses
The status of the sync task will be updated to reflect the progress of the task. The following statuses are known:
* http://lblod.data.gift/gelinkt-notuleren-mandatarissen-consumer-sync-task-statuses/not-started
* http://lblod.data.gift/gelinkt-notuleren-mandatarissen-consumer-sync-task-statuses/ongoing
* http://lblod.data.gift/gelinkt-notuleren-mandatarissen-consumer-sync-task-statuses/success
* http://lblod.data.gift/gelinkt-notuleren-mandatarissen-consumer-sync-task-statuses/failure

### Data flow
At regular intervals, the service will schedule a sync task. Execution of a task consists of the following steps:

1. Retrieve the timestamp to start the sync from
2. Query the producer service for all diff files since that specific timestamp
3. Download the content of each diff file
4. Process each diff file in order

During the processing of a diff file, the insert and delete changesets are processed in a different way

**Insert changeset**
Ingest the changeset in a temporary graph `TMP_INGEST_GRAPH`. Data cannot be ingested directly in the appropriate graph(s) since info to determine the correct graphs (e.g. the `rdf:type`) may still be missing.

**Delete changeset**
Apply a delete query triple per triple across all graphs (including the temporary graph)

At the end of each diff file processing, queries are executed to move data from the temporary graph to the appropriate graphs based on the `rdf:type` and authorization rules.

If one file fails to be ingested, the remaining files in the queue are blocked since the files must always be handled in order.

The service makes 2 core assumptions that must be respected at all times:
1. At any moment we know that the latest `ext:deltaUntil` timestamp on a task, either in failed/ongoing/success state, reflects the timestamp of the latest delta file that has been completly and successfully consumed
2. Maximum 1 sync task is running at any moment in time

### API
```
POST /ingest
```

Schedule and execute a sync task.

The endpoint is triggered internally at frequent intervals and should normally not be triggered by an external party.

